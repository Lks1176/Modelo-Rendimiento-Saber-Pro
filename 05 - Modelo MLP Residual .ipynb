{"cells":[{"cell_type":"markdown","id":"30d770aa","metadata":{"id":"30d770aa"},"source":["# Entrenamiento con MLP Residual\n","\n","Este cuaderno se centra exclusivamente en un MLP residual rápido para datos tabulares preprocesados. Incluye Optuna para tuning, validación estratificada (K=5), métricas por fold y exportación de artefactos.\n"]},{"cell_type":"code","execution_count":null,"id":"71d4a95d","metadata":{"id":"71d4a95d"},"outputs":[],"source":["\n","!pip install -q lightning optuna torchmetrics seaborn matplotlib"]},{"cell_type":"code","execution_count":null,"id":"f9aed8da","metadata":{"id":"f9aed8da","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764185872225,"user_tz":300,"elapsed":16950,"user":{"displayName":"CAMILO ANDRES CUELLAR BENITO","userId":"15391688419300175379"}},"outputId":"75b42519-5579-445b-c764-9ab296fef2d0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: Seed set to 42\n","INFO:lightning.fabric.utilities.seed:Seed set to 42\n"]}],"source":["import gc\n","import json\n","import math\n","import random\n","from collections import defaultdict\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import optuna\n","import pandas as pd\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import lightning.pytorch as pl\n","from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n","from lightning.pytorch.loggers import CSVLogger\n","from torchmetrics.classification import MulticlassAccuracy\n","\n","pl.seed_everything(42, workers=True)\n","optuna.logging.set_verbosity(optuna.logging.WARNING)"]},{"cell_type":"code","execution_count":null,"id":"abec39d4","metadata":{"id":"abec39d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764186024491,"user_tz":300,"elapsed":16,"user":{"displayName":"CAMILO ANDRES CUELLAR BENITO","userId":"15391688419300175379"}},"outputId":"0f1e3c34-03dc-4753-cf78-628a09c56b26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda | Artifacts: /content/artifacts\n"]}],"source":["# Configuración global y rutas relevantes\n","DATA_PATH = Path(\"processed_train.parquet\")\n","TARGET_COL = \"RENDIMIENTO_GLOBAL\"\n","CLASS_NAMES = [\"alto\", \"medio-alto\", \"medio-bajo\", \"bajo\"]\n","CLASS2IDX = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n","IDX2CLASS = {idx: cls for cls, idx in CLASS2IDX.items()}\n","\n","N_SPLITS = 5\n","RANDOM_STATE = 42\n","N_JOBS = 2\n","BATCH_SIZE_SPACE = [512, 1024, 2048, 4096]\n","ARTIFACT_DIR = Path(\"./artifacts\")\n","ARTIFACT_DIR.mkdir(exist_ok=True, parents=True)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Device: {device} | Artifacts: {ARTIFACT_DIR.resolve()}\")"]},{"cell_type":"code","execution_count":null,"id":"9c8917ab","metadata":{"id":"9c8917ab"},"outputs":[],"source":["# Utilidades compartidas\n","\n","def set_seed(seed: int = RANDOM_STATE) -> None:\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","\n","def make_dataloaders(X: np.ndarray, y: np.ndarray, train_idx: np.ndarray,\n","                     val_idx: np.ndarray, batch_size: int, num_workers: int = 2):\n","    \"\"\"Construye DataLoaders tensoriales con pin_memory para GPU.\"\"\"\n","    X_train = torch.from_numpy(X[train_idx]).float()\n","    y_train = torch.from_numpy(y[train_idx]).long()\n","    X_val = torch.from_numpy(X[val_idx]).float()\n","    y_val = torch.from_numpy(y[val_idx]).long()\n","\n","    train_loader = DataLoader(\n","        TensorDataset(X_train, y_train),\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=num_workers,\n","        pin_memory=(device == \"cuda\"),\n","        drop_last=False,\n","    )\n","    val_loader = DataLoader(\n","        TensorDataset(X_val, y_val),\n","        batch_size=min(batch_size, 2048),\n","        shuffle=False,\n","        num_workers=num_workers,\n","        pin_memory=(device == \"cuda\"),\n","    )\n","    return train_loader, val_loader\n","\n","\n","def collect_fold_metrics(name: str, fold_scores: list[dict]) -> pd.DataFrame:\n","    df = pd.DataFrame(fold_scores)\n","    summary = {\n","        \"model\": name,\n","        \"mean_acc\": df[\"accuracy\"].mean(),\n","        \"std_acc\": df[\"accuracy\"].std(ddof=0),\n","        \"min_acc\": df[\"accuracy\"].min(),\n","        \"max_acc\": df[\"accuracy\"].max(),\n","    }\n","    return df, summary\n","\n","\n","def logits_to_numpy(logits_list):\n","    return torch.cat(logits_list).softmax(dim=1).cpu().numpy()\n","\n","\n","def describe_class_balance(labels: np.ndarray):\n","    counts = pd.Series(labels).value_counts().sort_index()\n","    display(counts.rename(index=IDX2CLASS))\n"]},{"cell_type":"code","execution_count":null,"id":"43c2f7a4","metadata":{"id":"43c2f7a4","colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"status":"ok","timestamp":1764186027783,"user_tz":300,"elapsed":622,"user":{"displayName":"CAMILO ANDRES CUELLAR BENITO","userId":"15391688419300175379"}},"outputId":"078f8423-2042-4e1e-ecd1-ff6a239708e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape: (692500, 28) | Memoria ~155.1 MB\n"]},{"output_type":"display_data","data":{"text/plain":["alto          175619\n","medio-alto    171619\n","medio-bajo    172275\n","bajo          172987\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>alto</th>\n","      <td>175619</td>\n","    </tr>\n","    <tr>\n","      <th>medio-alto</th>\n","      <td>171619</td>\n","    </tr>\n","    <tr>\n","      <th>medio-bajo</th>\n","      <td>172275</td>\n","    </tr>\n","    <tr>\n","      <th>bajo</th>\n","      <td>172987</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Feature dims: 27\n"]}],"source":["# Carga de datos preprocesados y pipeline de referencia\n","assert DATA_PATH.exists(), f\"No se encontró {DATA_PATH}\"\n","\n","df = pd.read_parquet(DATA_PATH)\n","print(f\"Shape: {df.shape} | Memoria ~{df.memory_usage().sum() / 1e6:.1f} MB\")\n","\n","y = df[TARGET_COL].map(CLASS2IDX).to_numpy(dtype=np.int64)\n","X = df.drop(columns=[TARGET_COL]).to_numpy(dtype=np.float32)\n","\n","describe_class_balance(y)\n","print(f\"Feature dims: {X.shape[1]}\")\n","\n","del df\n","_ = gc.collect()"]},{"cell_type":"code","execution_count":null,"id":"f7c3c694","metadata":{"id":"f7c3c694","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764186031276,"user_tz":300,"elapsed":22,"user":{"displayName":"CAMILO ANDRES CUELLAR BENITO","userId":"15391688419300175379"}},"outputId":"7bf383b6-db9c-48d0-8eee-6960f8f7fe97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Folds preparados: 5\n"]}],"source":["# Definición de folds estratificados K=5\n","skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n","folds = list(skf.split(X, y))\n","print(f\"Folds preparados: {len(folds)}\")"]},{"cell_type":"code","execution_count":null,"id":"16c45239","metadata":{"id":"16c45239"},"outputs":[],"source":["# --- MLP Residual (ResNet-like) ---------------------------------------------\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, dim: int, dropout: float, residual_dropout: float):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(dim, dim),\n","            nn.Dropout(residual_dropout),\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)\n","\n","\n","class ResidualMLP(nn.Module):\n","    def __init__(self, input_dim: int, hidden_dim: int, depth: int,\n","                 dropout: float, residual_dropout: float, n_classes: int):\n","        super().__init__()\n","        self.input_proj = nn.Sequential(\n","            nn.LayerNorm(input_dim),\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.GELU(),\n","        )\n","        self.blocks = nn.ModuleList(\n","            [ResidualBlock(hidden_dim, dropout, residual_dropout) for _ in range(depth)]\n","        )\n","        self.head = nn.Sequential(\n","            nn.LayerNorm(hidden_dim),\n","            nn.Linear(hidden_dim, n_classes),\n","        )\n","\n","    def forward(self, x):\n","        h = self.input_proj(x)\n","        for block in self.blocks:\n","            h = block(h)\n","        return self.head(h)\n","\n","\n","class ResidualMLPModule(pl.LightningModule):\n","    def __init__(self, input_dim: int, n_classes: int, hidden_dim: int, depth: int,\n","                 dropout: float, residual_dropout: float, lr: float, weight_decay: float):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.model = ResidualMLP(input_dim, hidden_dim, depth, dropout, residual_dropout, n_classes)\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        logits = self(x)\n","        loss = self.criterion(logits, y)\n","        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        logits = self(x)\n","        loss = self.criterion(logits, y)\n","        preds = torch.argmax(logits, dim=1)\n","        acc = (preds == y).float().mean()\n","        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, sync_dist=True)\n","        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True, sync_dist=True)\n","        return {\"logits\": logits.detach(), \"targets\": y.detach()}\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n","        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n","        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n"]},{"cell_type":"code","execution_count":null,"id":"f3ba7923","metadata":{"id":"f3ba7923"},"outputs":[],"source":["# Optuna + entrenamiento para el MLP residual\n","\n","def tune_residual_mlp(X, y, folds, n_trials: int = 15):\n","    input_dim = X.shape[1]\n","\n","    def objective(trial: optuna.Trial) -> float:\n","        params = {\n","            \"hidden_dim\": trial.suggest_categorical(\"hidden_dim\", [256, 384, 512, 640]),\n","            \"depth\": trial.suggest_int(\"depth\", 3, 6),\n","            \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.3),\n","            \"residual_dropout\": trial.suggest_float(\"residual_dropout\", 0.0, 0.2),\n","            \"lr\": trial.suggest_float(\"lr\", 5e-4, 5e-3, log=True),\n","            \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True),\n","            \"batch_size\": trial.suggest_categorical(\"batch_size\", BATCH_SIZE_SPACE),\n","            \"max_epochs\": trial.suggest_int(\"max_epochs\", 12, 30),\n","        }\n","        train_idx, val_idx = folds[0]\n","        train_loader, val_loader = make_dataloaders(X, y, train_idx, val_idx, params[\"batch_size\"])\n","        module = ResidualMLPModule(\n","            input_dim=input_dim,\n","            n_classes=len(CLASS_NAMES),\n","            hidden_dim=params[\"hidden_dim\"],\n","            depth=params[\"depth\"],\n","            dropout=params[\"dropout\"],\n","            residual_dropout=params[\"residual_dropout\"],\n","            lr=params[\"lr\"],\n","            weight_decay=params[\"weight_decay\"],\n","        )\n","        trainer = pl.Trainer(\n","            accelerator=\"gpu\" if device == \"cuda\" else \"cpu\",\n","            devices=1,\n","            precision=\"16-mixed\" if device == \"cuda\" else \"32-true\",\n","            max_epochs=params[\"max_epochs\"],\n","            enable_checkpointing=False,\n","            logger=False,\n","            enable_progress_bar=False,\n","        )\n","        trainer.fit(module, train_loader, val_loader)\n","        val_acc = float(trainer.callback_metrics.get(\"val_acc\", torch.tensor(0.0)).cpu())\n","        torch.cuda.empty_cache()\n","        return val_acc\n","\n","    study = optuna.create_study(direction=\"maximize\", study_name=\"residual_mlp\")\n","    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n","    return study, study.best_params\n","\n","\n","def train_residual_mlp_cv(best_params: dict, X, y, folds):\n","    params = best_params.copy()\n","    batch_size = params.pop(\"batch_size\")\n","    max_epochs = params.pop(\"max_epochs\")\n","    input_dim = X.shape[1]\n","\n","    oof_pred = np.zeros((len(y), len(CLASS_NAMES)), dtype=np.float32)\n","    fold_scores = []\n","    checkpoints = []\n","\n","    for fold_id, (tr_idx, val_idx) in enumerate(folds):\n","        print(f\"[ResidualMLP] Fold {fold_id}\")\n","        train_loader, val_loader = make_dataloaders(X, y, tr_idx, val_idx, batch_size)\n","        module = ResidualMLPModule(input_dim=input_dim, n_classes=len(CLASS_NAMES), **params)\n","        callbacks = [\n","            EarlyStopping(monitor=\"val_acc\", patience=5, mode=\"max\"),\n","            ModelCheckpoint(\n","                dirpath=ARTIFACT_DIR / f\"residual_mlp_fold{fold_id}\",\n","                filename=\"res-mlp-{epoch:02d}-{val_acc:.4f}\",\n","                monitor=\"val_acc\",\n","                mode=\"max\",\n","                save_top_k=1,\n","            ),\n","        ]\n","        logger = CSVLogger(save_dir=ARTIFACT_DIR / f\"logs_res_fold{fold_id}\", name=\"resmlp\")\n","        trainer = pl.Trainer(\n","            accelerator=\"gpu\" if device == \"cuda\" else \"cpu\",\n","            devices=1,\n","            precision=\"16-mixed\" if device == \"cuda\" else \"32-true\",\n","            max_epochs=max_epochs,\n","            callbacks=callbacks,\n","            logger=logger,\n","            gradient_clip_val=1.0,\n","        )\n","        trainer.fit(module, train_loader, val_loader)\n","        best_ckpt = callbacks[1].best_model_path\n","        checkpoints.append(best_ckpt)\n","        best_model = ResidualMLPModule.load_from_checkpoint(best_ckpt)\n","        best_model.to(device).eval()\n","        val_logits = []\n","        with torch.no_grad():\n","            for xb, yb in val_loader:\n","                xb = xb.to(device)\n","                val_logits.append(best_model(xb).cpu())\n","        probs = torch.cat(val_logits).softmax(dim=1).numpy()\n","        oof_pred[val_idx] = probs\n","        preds = probs.argmax(axis=1)\n","        fold_scores.append({\"fold\": fold_id, \"accuracy\": accuracy_score(y[val_idx], preds)})\n","        del best_model\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    return {\n","        \"name\": \"ResidualMLP\",\n","        \"best_params\": best_params,\n","        \"fold_metrics\": fold_scores,\n","        \"oof_predictions\": oof_pred,\n","        \"model_paths\": checkpoints,\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"81e79c31","metadata":{"id":"81e79c31","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b44000343f574dd2b9bf85d852543fd5","c64bced6fa6949aa8aedc7ebe262906a","10cd42d132454f06aac303a2ffd04871","a08401f70613496291066539b246cc3d","27cd4f15d8ab490fa46f0b0a74237f68","4b938008d8034ffa91b94314e7e1f272","9d96007dcaf54ee29a34a3c2bf9fc878","f2dc467c27a04fd5a5f65a4f0daeb43a","0775d382748843ec92a0bb616e74cdb3","8f1819aa338648c9884db45460ad835d","cf6c772e7ba948d98a70e7960e151fe7"]},"outputId":"ddae2408-4ea2-4b8f-d2c4-a53ed1d312d6"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b44000343f574dd2b9bf85d852543fd5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stderr","text":["INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.1 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.1 M     Trainable params\n","0         Non-trainable params\n","2.1 M     Total params\n","8.491     Total estimated model params size (MB)\n","42        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.1 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.1 M     Trainable params\n","0         Non-trainable params\n","2.1 M     Total params\n","8.491     Total estimated model params size (MB)\n","42        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=26` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=26` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 669 K  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","669 K     Trainable params\n","0         Non-trainable params\n","669 K     Total params\n","2.677     Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 669 K  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","669 K     Trainable params\n","0         Non-trainable params\n","669 K     Total params\n","2.677     Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=14` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=27` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=27` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 405 K  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","405 K     Trainable params\n","0         Non-trainable params\n","405 K     Total params\n","1.620     Total estimated model params size (MB)\n","34        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 405 K  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","405 K     Trainable params\n","0         Non-trainable params\n","405 K     Total params\n","1.620     Total estimated model params size (MB)\n","34        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=19` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=19` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 3.3 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","3.3 M     Trainable params\n","0         Non-trainable params\n","3.3 M     Total params\n","13.235    Total estimated model params size (MB)\n","42        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 3.3 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","3.3 M     Trainable params\n","0         Non-trainable params\n","3.3 M     Total params\n","13.235    Total estimated model params size (MB)\n","42        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=23` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=23` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=19` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=19` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=25` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=25` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 3.2 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","3.2 M     Trainable params\n","0         Non-trainable params\n","3.2 M     Total params\n","12.702    Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 3.2 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","3.2 M     Trainable params\n","0         Non-trainable params\n","3.2 M     Total params\n","12.702    Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=16` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=16` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 4.1 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","4.1 M     Trainable params\n","0         Non-trainable params\n","4.1 M     Total params\n","16.522    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 4.1 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","4.1 M     Trainable params\n","0         Non-trainable params\n","4.1 M     Total params\n","16.522    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=15` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 5.0 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","5.0 M     Trainable params\n","0         Non-trainable params\n","5.0 M     Total params\n","19.810    Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 5.0 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","5.0 M     Trainable params\n","0         Non-trainable params\n","5.0 M     Total params\n","19.810    Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=15` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 902 K  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","902 K     Trainable params\n","0         Non-trainable params\n","902 K     Total params\n","3.610     Total estimated model params size (MB)\n","34        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 902 K  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","902 K     Trainable params\n","0         Non-trainable params\n","902 K     Total params\n","3.610     Total estimated model params size (MB)\n","34        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 2.6 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","0         Non-trainable params\n","2.6 M     Total params\n","10.597    Total estimated model params size (MB)\n","50        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 3.2 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","3.2 M     Trainable params\n","0         Non-trainable params\n","3.2 M     Total params\n","12.702    Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 3.2 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","3.2 M     Trainable params\n","0         Non-trainable params\n","3.2 M     Total params\n","12.702    Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=30` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=28` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=28` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO: `Trainer.fit` stopped: `max_epochs=28` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=28` reached.\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name      | Type             | Params | Mode \n","-------------------------------------------------------\n","0 | model     | ResidualMLP      | 1.8 M  | train\n","1 | criterion | CrossEntropyLoss | 0      | train\n","-------------------------------------------------------\n","1.8 M     Trainable params\n","0         Non-trainable params\n","1.8 M     Total params\n","7.167     Total estimated model params size (MB)\n","58        Modules in train mode\n","0         Modules in eval mode\n"]}],"source":["# Tuning y entrenamiento del MLP residual\n","N_TRIALS_RES = 20\n","res_study, res_best_params = tune_residual_mlp(X, y, folds, n_trials=N_TRIALS_RES)\n","print(f\"Residual params: {json.dumps(res_best_params, indent=2)}\")\n","\n","res_results = train_residual_mlp_cv(res_best_params, X, y, folds)\n","res_fold_df, res_summary = collect_fold_metrics(res_results[\"name\"], res_results[\"fold_metrics\"])\n","res_fold_df"]},{"cell_type":"code","execution_count":null,"id":"25b32070","metadata":{"id":"25b32070"},"outputs":[],"source":["# Evaluación final del Residual MLP\n","res_summary"]},{"cell_type":"code","execution_count":null,"id":"392c9764","metadata":{"id":"392c9764"},"outputs":[],"source":["# Matriz de confusión y reporte del Residual MLP\n","best_oof = res_results[\"oof_predictions\"]\n","y_pred = best_oof.argmax(axis=1)\n","acc = accuracy_score(y, y_pred)\n","print(f\"Accuracy OOF global Residual MLP: {acc:.4f}\")\n","\n","conf_mat = confusion_matrix(y, y_pred)\n","plt.figure(figsize=(6, 5))\n","sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n","            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n","plt.xlabel(\"Predicción\")\n","plt.ylabel(\"Real\")\n","plt.title(\"Matriz de confusión - Residual MLP\")\n","plt.tight_layout()\n","plt.show()\n","\n","print(classification_report(y, y_pred, target_names=CLASS_NAMES))"]},{"cell_type":"code","execution_count":null,"id":"aef612c1","metadata":{"id":"aef612c1"},"outputs":[],"source":["# Exportación e inferencia con Residual MLP\n","pipeline = joblib.load(PIPELINE_PATH)\n","\n","best_hparams = {k: v for k, v in res_results[\"best_params\"].items()\n","                if k in [\"hidden_dim\", \"depth\", \"dropout\", \"residual_dropout\", \"lr\", \"weight_decay\"]}\n","\n","sample_checkpoint = res_results[\"model_paths\"][0] if res_results[\"model_paths\"] else None\n","print(f\"Checkpoint de ejemplo: {sample_checkpoint}\")\n","\n","\n","def predict_with_residual_mlp(raw_df: pd.DataFrame, checkpoint_path: str) -> pd.DataFrame:\n","    assert checkpoint_path is not None, \"No hay checkpoint disponible\"\n","    processed = pipeline.transform(raw_df)\n","    tensor = torch.from_numpy(np.asarray(processed, dtype=np.float32))\n","    model = ResidualMLPModule.load_from_checkpoint(\n","        checkpoint_path,\n","        input_dim=tensor.shape[1],\n","        n_classes=len(CLASS_NAMES),\n","        **best_hparams,\n","    )\n","    model.eval()\n","    with torch.no_grad():\n","        logits = model(tensor)\n","        probas = torch.softmax(logits, dim=1).numpy()\n","    preds = probas.argmax(axis=1)\n","    result = raw_df.copy()\n","    result[\"RENDIMIENTO_GLOBAL_PRED\"] = [IDX2CLASS[idx] for idx in preds]\n","    for idx, cls in enumerate(CLASS_NAMES):\n","        result[f\"proba_{cls}\"] = probas[:, idx]\n","    return result\n","\n","# Ejemplo de uso:\n","# sample = some_raw_df.head(3)\n","# predict_with_residual_mlp(sample, sample_checkpoint)"]},{"cell_type":"markdown","id":"80b47fbf","metadata":{"id":"80b47fbf"},"source":["## Notas prácticas y bibliografía resumida\n","- **Boosting vs. deep tabular**: LightGBM/CatBoost siguen dominando con datos medianos-grandes, especialmente cuando las features ya fueron cuidadosamente codificadas. Requiere poca ingeniería de hiperparámetros y ofrece interpretabilidad vía importancia de variables.\n","- **FT-Transformer / SAINT**: útiles cuando hay fuertes interacciones no lineales entre atributos heterogéneos y se dispone de GPU. Regulariza con dropout y weight decay; usa lotes grandes (512–4096) y AMP para saturar la T4.\n","- **ResNet tabular**: baseline estable para escenarios donde se quiera una red poco compleja y rápida de ajustar; añadir stochastic depth o mixup ayuda si aparece overfitting.\n","- **TabPFN**: excelente para prototipar cuando el dataset es pequeño (<50k muestras) o se requiere una predicción rápida sin tuning, pero escala de manera cuadrática por lo que aquí se limita a un muestreo.\n","- **Regularización**: prioriza early stopping + bagging en boosting; en deep models combina dropout, weight decay y augmentation (CutMix tabular) si la precisión se estanca.\n","- **Reporte final**: comunica accuracy macro, matriz de confusión, curvas de calibración/Roc por clase (si aplican) y tiempos de entrenamiento por modelo.\n","\n","**Bibliografía 2020–2025**\n","1. Gorishniy et al., *Revisiting Deep Learning Models for Tabular Data* (NeurIPS 2021). https://arxiv.org/abs/2106.11959\n","2. Gorishniy et al., *FT-Transformer: Fast and Accurate Modeling of Tabular Data* (ICML 2021 Workshop). https://arxiv.org/abs/2106.01126\n","3. Somepalli et al., *SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pretraining* (NeurIPS 2021). https://arxiv.org/abs/2106.01342\n","4. Hollmann et al., *TabPFN: A Transformer that Solves Small Tabular Classification Problems in a Second* (NeurIPS 2022). https://arxiv.org/abs/2207.01848\n","5. Misra et al., *A Survey on Deep Learning for Tabular Data* (ACM Computing Surveys 2023). https://arxiv.org/abs/2207.07454"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"10pfwrHuvl7mjlQt1C5Vu4efRPGgEkjDU","timestamp":1764165750668}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b44000343f574dd2b9bf85d852543fd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c64bced6fa6949aa8aedc7ebe262906a","IPY_MODEL_10cd42d132454f06aac303a2ffd04871","IPY_MODEL_a08401f70613496291066539b246cc3d"],"layout":"IPY_MODEL_27cd4f15d8ab490fa46f0b0a74237f68"}},"c64bced6fa6949aa8aedc7ebe262906a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b938008d8034ffa91b94314e7e1f272","placeholder":"​","style":"IPY_MODEL_9d96007dcaf54ee29a34a3c2bf9fc878","value":"Best trial: 15. Best value: 0.418318:  85%"}},"10cd42d132454f06aac303a2ffd04871":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2dc467c27a04fd5a5f65a4f0daeb43a","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0775d382748843ec92a0bb616e74cdb3","value":17}},"a08401f70613496291066539b246cc3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f1819aa338648c9884db45460ad835d","placeholder":"​","style":"IPY_MODEL_cf6c772e7ba948d98a70e7960e151fe7","value":" 17/20 [1:19:28&lt;16:19, 326.34s/it]"}},"27cd4f15d8ab490fa46f0b0a74237f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b938008d8034ffa91b94314e7e1f272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d96007dcaf54ee29a34a3c2bf9fc878":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2dc467c27a04fd5a5f65a4f0daeb43a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0775d382748843ec92a0bb616e74cdb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f1819aa338648c9884db45460ad835d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6c772e7ba948d98a70e7960e151fe7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}